# План разработки Easy Lessons Bot

## Отчет по прогрессу
- **Текущая итерация**: 16/16 ✅
- **Статус**: Мультимедиа расширения полностью реализованы и протестированы
- **Последнее обновление**: 2025-01-27
- **Достижения**: 
  - ✅ Полная функциональность бота с двухмодельной архитектурой
  - ✅ Персистентность данных с SQLite и graceful degradation
  - ✅ Docker контейнеризация с volumes для данных
  - ✅ Comprehensive тестирование (137+ тестов)
  - ✅ Автоматические миграции БД
  - ✅ Логирование и мониторинг
  - ✅ **Завершено**: Мультимедиа расширения (аудио, изображения, API интеграции)

---

## Итерация 1: Базовая настройка проекта ✅
- [x] Создать структуру директорий согласно @vision.md
- [x] Настроить pyproject.toml с зависимостями (uv, aiogram, openai, pydantic-settings)
- [x] Создать Makefile с основными командами (install, lint, fmt, test, run)
- [x] Настроить базовое логирование в /log/app.log

## Итерация 2: Конфигурация и настройки ✅
- [x] Создать settings/config.py с pydantic-settings
- [x] Добавить валидацию обязательных переменных (TELEGRAM_BOT_TOKEN, OPENROUTER_API_KEY)
- [x] Создать .env.example с примерами переменных окружения
- [x] Протестировать загрузку конфигурации

## Итерация 3: Базовый Telegram бот ✅
- [x] Создать app/main.py как точку входа
- [x] Реализовать базовую инициализацию aiogram бота
- [x] Добавить обработчик команды /start
- [x] Протестировать подключение к Telegram API

## Итерация 4: LLM клиент ✅
- [x] Создать core/llm_client.py с openai клиентом для OpenRouter
- [x] Реализовать базовый запрос к LLM с таймаутом и ретраями
- [x] Добавить логирование запросов и ответов
- [x] Протестировать подключение к OpenRouter API

## Итерация 5: Управление состоянием ✅
- [x] Создать core/session_state.py для in-memory состояния
- [x] Реализовать SessionState с chat_id, active_topic, understanding_level
- [x] Добавить управление историей сообщений (лимит 30)
- [x] Протестировать сохранение и получение состояния

## Итерация 6: Система промптов ✅
- [x] Создать core/prompt_store.py для управления промптами
- [x] Добавить базовые системные промпты в core/prompts/
- [x] Реализовать сборку контекста для LLM
- [x] Протестировать генерацию промптов

## Итерация 7: Обработка текстовых сообщений ✅
- [x] Создать bot/handlers.py с обработчиками сообщений
- [x] Реализовать обработку свободного текста пользователя
- [x] Интегрировать LLM клиент с обработчиками
- [x] Протестировать полный цикл: сообщение → LLM → ответ

## Итерация 8: Новая диалоговая логика (двухмодельная схема)
- [x] Обновить структуру `SessionState` под динамический контекст (scenario, question, topic, is_new_question, is_new_topic, understanding_level [0..9], previous_understanding_level, previous_topic, user_preferences, messages)
- [x] Реализовать интеграцию вспомогательной модели: `analyze_context_with_auxiliary_model()` (5 последних сообщений + контекст → scenario, topic, question, understanding_level, is_new_*)
- [x] Добавить `Context Processor` для объединения ответа вспомогательной модели с состоянием сессии и выбора сценария; добавить рекомендацию при уровне ≥ 9
- [x] Обновить `Prompt Store`: сборка системного промпта = базовый + динамический контекст + промпт сценария; системный промпт закрепляется первым и не обрезается
- [x] Добавить промпты сценариев: `core/prompts/scenarios/system_discussion.txt`, `system_explanation.txt`, `system_unknown.txt`; обновить базовый промпт
- [x] Обновить `bot/handlers.py` под новый поток: add_message → analyze_context → process_context → build_dialog_context → запрос к диалоговой модели → add_message → send
- [x] Добавить Readiness Checker (`core/readiness/checker.py`) и Welcome Messages Store (`core/welcome_messages/` + случайный выбор); обновить `/start`
- [x] Добавить минимальные тесты для `Context Processor` и `Prompt Store` (моки LLM); сценарии discussion/explanation/unknown

## Итерация 9: Обработка ошибок и надежность ✅
- [x] Добавить обработку ошибок LLM (таймауты, 5xx)
- [x] Реализовать user-friendly сообщения об ошибках
- [x] Добавить graceful degradation при сбоях
- [x] Протестировать поведение при ошибках

## Итерация 10: Тестирование ✅
- [x] Создать unit-тесты для core/ модулей
- [x] Добавить тесты для LLM клиента с моками
- [x] Создать тесты для обработчиков бота
- [x] Достичь покрытия 60-70% ключевой логики (факт: ~82%)

## Итерация 11: Docker и деплой ✅
- [x] Создать Dockerfile на базе python:3.12-slim
- [x] Настроить установку зависимостей через uv
- [x] Добавить команды docker-build и docker-run в Makefile
- [x] Протестировать запуск в контейнере

## Итерация 12: Улучшения Docker-контейнера ✅
- [x] Создать .dockerignore для оптимизации сборки
- [x] Улучшить Dockerfile с multi-stage build и health check
- [x] Создать docker-compose.yml для dev/prod режимов
- [x] Расширить Makefile полным набором Docker команд
- [x] Обновить документацию с новыми командами

## Итерация 13: Финальная интеграция и документация ✅
- [x] Создать README.md с инструкциями по запуску
- [x] Добавить конфигурацию pre-commit с ruff и pytest
- [x] Прогнать хуки pre-commit, убедиться в чистоте
- [x] Добавить примеры использования бота
- [x] Провести полное тестирование всех функций

## Итерация 14: Персистентность данных (SQLite) ✅
> **Контекст**: Детальная техническая спецификация в @persistence.md

### Этап 1: Базовая инфраструктура ✅
- [x] Создать директорию `core/persistence/` и базовые файлы (структура в @persistence.md)
- [x] Добавить SQLAlchemy 2.0 в зависимости (pyproject.toml)
- [x] Создать `core/persistence/database.py` с DatabaseManager (принципы в @persistence.md)
- [x] Реализовать подключение к SQLite с async/await
- [x] Протестировать создание и подключение к БД

### Этап 2: Модели данных ✅
- [x] Создать `core/persistence/models.py` с SQLAlchemy моделями
- [x] Реализовать модель Sessions с полями: chat_id, scenario, question, topic, is_new_question, is_new_topic, understanding_level, previous_understanding_level, previous_topic, user_preferences, created_at, updated_at (схема в @persistence.md)
- [x] Реализовать модель Messages с связью к Sessions (схема в @persistence.md)
- [x] Реализовать модель Migrations для версионирования (схема в @persistence.md)
- [x] Протестировать создание таблиц

### Этап 3: Система миграций ✅
- [x] Создать `core/persistence/migrations/manager.py`
- [x] Реализовать MigrationManager с автоматическим применением (система в @persistence.md)
- [x] Создать `core/persistence/migrations/versions/001_initial_schema.py`
- [x] Добавить отслеживание примененных миграций
- [x] Протестировать применение миграций при старте

### Этап 4: Repository слой ✅
- [x] Создать `core/persistence/repositories.py`
- [x] Реализовать SessionRepository для CRUD операций (Repository pattern в @persistence.md)
- [x] Добавить методы загрузки и сохранения сессий
- [x] Реализовать операции с сообщениями
- [x] Протестировать все операции с данными

### Этап 5: Интеграция с существующим кодом ✅
- [x] Создать `core/persistence/session_adapter.py`
- [x] Реализовать PersistenceAdapter для интеграции с SessionManager (архитектура в @persistence.md)
- [x] Обновить `core/session_state.py` для работы с персистентностью
- [x] Добавить graceful degradation при недоступности БД (принципы в @persistence.md)
- [x] Протестировать совместимость с существующим кодом

### Этап 6: Конфигурация и настройки ✅
- [x] Обновить `settings/config.py` с новыми переменными БД (переменные в @persistence.md)
- [x] Добавить DATABASE_ENABLED, DATABASE_PATH, DATABASE_CLEANUP_HOURS
- [x] Реализовать валидацию настроек БД
- [x] Обновить .env.example с примерами переменных
- [x] Протестировать загрузку конфигурации

### Этап 7: Docker интеграция ✅
- [x] Обновить Dockerfile для создания директории /app/data (деплой в @persistence.md)
- [x] Обновить docker-compose.yml с volume для данных
- [x] Добавить переменные окружения для БД в docker-compose
- [x] Протестировать запуск в контейнере с персистентностью
- [x] Убедиться в сохранении данных между перезапусками

### Этап 8: Тестирование и оптимизация ✅
- [x] Создать тесты для DatabaseManager с моками
- [x] Добавить тесты для SessionRepository
- [x] Создать тесты для PersistenceAdapter
- [x] Протестировать graceful degradation
- [x] Добавить тесты интеграции с полным циклом
- [x] Протестировать производительность операций с БД

### Этап 9: Логирование и мониторинг ✅
- [x] Добавить логирование операций с БД
- [x] Реализовать логирование времени выполнения запросов
- [x] Добавить логирование ошибок БД с трассировкой
- [x] Протестировать логирование всех операций
- [x] Убедиться в отсутствии PII в логах

### Этап 10: Финальная интеграция ✅
- [x] Протестировать полный цикл: сообщение → БД → ответ
- [x] Проверить сохранение состояния между перезапусками
- [x] Протестировать работу с множественными пользователями
- [x] Убедиться в корректной работе graceful degradation
- [x] Провести нагрузочное тестирование

---

## Итерация 15: Автоматизация версионирования и отображение версии в логах ✅
> **Контекст**: Добавить автоматическое отслеживание версий и отображение в логах для лучшего мониторинга

### Этап 1: Отображение версии в логах
- [x] Добавить импорт версии в app/main.py из pyproject.toml
- [x] Обновить логирование запуска с отображением версии бота
- [x] Добавить версию в health check логи
- [x] Протестировать отображение версии в логах

### Этап 2: Автоматическое версионирование
- [x] Настроить автоматическое обновление версии при коммитах (git hooks)
- [x] Добавить версионирование Docker образов с тегами
- [x] Создать скрипт для автоматического bump версии
- [x] Интегрировать версионирование в CI/CD pipeline

### Этап 3: Отслеживание изменений
- [x] Добавить отображение git commit hash в логах
- [x] Добавить метаданные версии в Docker labels
- [x] Создать команду для получения информации о версии через Telegram
- [x] Протестировать отслеживание версий в production

---

## Итерация 16: Мультимедиа расширения (аудио и фото) ✅
> **Контекст**: Детальная техническая спецификация в @vision_multimedia.md
> 
> **Статус**: Полностью реализовано и протестировано. Все API интеграции работают корректно.
> Реализована интеграция с Whisper API, Vision API и скачивание файлов из Telegram.

### Этап 1: Обновление зависимостей и конфигурации ✅
- [x] Добавить новые зависимости в pyproject.toml (openai-whisper, Pillow, python-magic)
- [x] Обновить settings/config.py с новыми переменными окружения (AUDIO_ENABLED, IMAGE_ANALYSIS_ENABLED, WHISPER_MODEL, VISION_MODEL, MAX_IMAGE_SIZE, MAX_AUDIO_DURATION, TEMP_DIR)
- [x] Обновить .env.example с примерами новых переменных
- [x] Протестировать загрузку обновленной конфигурации

### Этап 2: Базовая инфраструктура медиа-обработки ✅
- [x] Создать директорию `core/multimedia_prompts/` с промптами для медиа
- [x] Создать `core/media_processor.py` — основной координатор медиа-обработки
- [x] Создать `core/context_matcher.py` — сопоставление медиа-контента с контекстом диалога
- [x] Создать директорию `data/temp/` для временных медиа-файлов
- [x] Протестировать базовую инфраструктуру

### Этап 3: Обработка аудио ✅
- [x] Создать `core/audio_handler.py` для работы с голосовыми сообщениями
- [x] Реализовать скачивание аудио-файлов из Telegram
- [x] Интегрировать Whisper API для распознавания речи
- [x] Добавить анализ транскрипта через LLM для определения намерения
- [x] Реализовать опциональный синтез речи (TTS)
- [x] Протестировать полный цикл обработки аудио

### Этап 4: Обработка изображений ✅
- [x] Создать `core/image_analyzer.py` для анализа изображений через GPT-4 Vision API
- [x] Реализовать скачивание изображений из Telegram
- [x] Интегрировать GPT-4 Vision API для анализа изображений
- [x] Реализовать определение типа контента (текст, задачи, диаграммы, фото)
- [x] Добавить извлечение и анализ текста на изображениях
- [x] Протестировать анализ различных типов изображений

### Этап 5: Медиа-хэндлеры для бота ✅
- [x] Создать `bot/media_handlers.py` для обработки медиа-сообщений
- [x] Реализовать обработчики голосовых сообщений
- [x] Реализовать обработчики фото и изображений
- [x] Интегрировать медиа-хэндлеры с основным ботом
- [x] Протестировать обработку медиа-сообщений

### Этап 6: Расширение модели данных ✅
- [x] Создать миграцию `002_add_media_support.py` для добавления поддержки медиа
- [x] Добавить таблицу MediaFiles в модель данных
- [x] Расширить модель Sessions новыми полями (media_context, audio_enabled, image_analysis_history)
- [x] Обновить SessionRepository для работы с медиа-данными
- [x] Протестировать обновленную модель данных

### Этап 7: Сценарии обработки медиа ✅
- [x] Реализовать контекстный анализ изображений (связь с текущим диалогом)
- [x] Добавить сценарий объяснения тем по фото учебных материалов
- [x] Реализовать сценарий решения задач по фото
- [x] Добавить сценарий уточняющих вопросов для неопределенного контента
- [x] Протестировать все сценарии обработки медиа

### Этап 8: Интеграция с существующей логикой ✅
- [x] Обновить `core/session_state.py` для работы с медиа-контекстом
- [x] Интегрировать медиа-анализ с Context Processor
- [x] Обновить Prompt Store для работы с медиа-данными
- [x] Добавить медиа-контекст в системные промпты
- [x] Протестировать интеграцию с существующей логикой

### Этап 9: Docker и деплой обновления ✅
- [x] Обновить Dockerfile для поддержки медиа-зависимостей
- [x] Добавить системные библиотеки для обработки медиа (PIL)
- [x] Обновить docker-compose.yml с новыми переменными окружения
- [x] Добавить volume для временных медиа-файлов
- [x] Протестировать запуск в контейнере с медиа-функциями

### Этап 10: Тестирование мультимедиа ✅
- [x] Создать unit-тесты для MediaProcessor
- [x] Добавить тесты для AudioHandler с моками Whisper API
- [x] Создать тесты для ImageAnalyzer с моками Vision API
- [x] Добавить тесты для ContextMatcher
- [x] Создать интеграционные тесты для полного цикла медиа-обработки
- [x] Протестировать graceful degradation при недоступности медиа-сервисов

### Этап 11: Логирование и мониторинг медиа ✅
- [x] Добавить логирование операций с медиа-файлами
- [x] Реализовать логирование времени обработки аудио и изображений
- [x] Добавить метрики по типам медиа-контента
- [x] Реализовать логирование ошибок медиа-обработки
- [x] Протестировать логирование всех медиа-операций

### Этап 12: Безопасность и оптимизация ✅
- [x] Реализовать валидацию типов медиа-файлов
- [x] Добавить проверку размеров файлов и лимиты
- [x] Реализовать автоматическое удаление временных файлов
- [x] Добавить кеширование результатов анализа изображений
- [x] Протестировать безопасность и производительность

### Этап 13: Финальная интеграция и тестирование ✅
- [x] Протестировать полный цикл: медиа-сообщение → анализ → ответ
- [x] Проверить работу с множественными пользователями и медиа-файлами
- [x] Протестировать graceful degradation при ошибках медиа-обработки
- [x] Провести нагрузочное тестирование медиа-функций
- [x] Убедиться в корректной работе всех сценариев

### Этап 14: Документация и примеры ✅
- [x] Обновить README.md с инструкциями по медиа-функциям
- [x] Добавить примеры использования аудио и фото
- [x] Создать документацию по настройке медиа-сервисов
- [x] Добавить troubleshooting для медиа-функций
- [x] Протестировать документацию

---

---

## Дополнительные задачи

### Тикет: Локальная модель Whisper для транскрипции аудио

**Проблема**: OpenRouter не поддерживает Whisper API (ошибка 405 Method Not Allowed), что делает транскрипцию аудиосообщений невозможной.

**Решение**: Реализовать локальную модель Whisper для транскрипции аудио.

**Задачи**:
- [ ] Установить библиотеку `whisper` от OpenAI
- [ ] Добавить настройку для выбора модели Whisper (tiny, base, small, medium, large)
- [ ] Реализовать локальную транскрипцию в `AudioHandler`
- [ ] Добавить кэширование результатов транскрипции
- [ ] Оптимизировать производительность (GPU ускорение если доступно)
- [ ] Добавить fallback на OpenAI API если локальная модель недоступна
- [ ] Обновить документацию по настройке Whisper
- [ ] Протестировать качество транскрипции на русском языке

**Приоритет**: Высокий (блокирует основную функциональность)

**Зависимости**: 
- PyTorch для работы с моделями
- FFmpeg для обработки аудио форматов
- Достаточно места на диске для моделей (от 39MB для tiny до 3GB для large)

### Тикет: Унификация пайплайнов обработки сообщений

**Проблема**: Аудиосообщения обрабатываются через отдельный пайплайн медиа-обработки, а не через основной пайплайн текстовых сообщений. Это создает архитектурную несогласованность и дублирование логики.

**Решение**: После транскрипции аудио, полученный текст должен передаваться в основной пайплайн обработки текстовых сообщений для единообразной обработки.

**Задачи**:
- [ ] Создать единый интерфейс для обработки сообщений (текст + транскрибированный аудио)
- [ ] Модифицировать обработчик голосовых сообщений для передачи транскрибированного текста в основной пайплайн
- [ ] Убрать дублирование логики анализа намерений между медиа-пайплайном и текстовым пайплайном
- [ ] Обеспечить единообразное логирование и обработку ошибок
- [ ] Протестировать, что аудио и текст проходят одинаковые этапы обработки
- [ ] Обновить документацию архитектуры

**Приоритет**: Средний (архитектурное улучшение)

**Зависимости**: 
- Завершение реализации локальной модели Whisper
- Анализ текущей архитектуры пайплайнов

---

## Критерии готовности каждой итерации
- Код компилируется без ошибок
- Все тесты проходят
- Функционал можно протестировать вручную
- Логирование работает корректно
- Соблюдены принципы KISS и YAGNI
- Медиа-функции работают стабильно
- Graceful degradation при недоступности медиа-сервисов
