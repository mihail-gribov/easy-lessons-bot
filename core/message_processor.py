"""Unified message processor for handling all types of messages."""

import logging
from typing import Any, Dict, Optional

from aiogram.types import Message

from core.context_processor import process_aux_result
from core.error_messages import get_user_friendly_error_message
from core.llm_client import LLMError, get_llm_client
from core.prompt_store import get_prompt_store
from core.session_state import get_session_manager

logger = logging.getLogger(__name__)


class UnifiedMessageProcessor:
    """Unified processor for all message types (text, voice, photo, document)."""

    def __init__(self):
        """Initialize unified message processor."""
        self.session_manager = get_session_manager()
        self.prompt_store = get_prompt_store()
        self.llm_client = get_llm_client()

    async def process_message(
        self, message: Message, message_type: str = "text"
    ) -> Optional[str]:
        """
        Process any type of message through unified pipeline.

        Args:
            message: Telegram message object
            message_type: Type of message ('text', 'voice', 'photo', 'document')

        Returns:
            Response text or None if error
        """
        chat_id = message.chat.id
        logger.info(
            "Processing %s message from user %s", message_type, chat_id
        )

        try:
            # Get session state
            session = await self.session_manager.get_session(chat_id)

            # Extract content based on message type
            content = await self._extract_message_content(message, message_type)
            if not content:
                return "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð²Ð°ÑˆÐµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ."

            # Add user message to session history
            session.add_message("user", content)

            # Two-model flow: auxiliary analysis â†’ context processing â†’ dialog model
            aux = await self.prompt_store.analyze_context_with_auxiliary_model(
                session, content
            )
            dynamic_ctx = process_aux_result(session, aux)

            # Build messages for dialog model
            messages = self.prompt_store.build_dialog_context(
                session, dynamic_ctx, content
            )

            # Generate response with graceful degradation
            try:
                response_text = await self.llm_client.generate_response(
                    messages=messages,
                    temperature=0.3,
                    max_tokens=512,
                )
            except LLMError as e:
                logger.warning("Dialog model failed, using graceful degradation: %s", e)
                from core.graceful_degradation import get_graceful_degradation_manager

                degradation_manager = get_graceful_degradation_manager()
                response_text = degradation_manager.handle_dialog_model_failure(
                    session, content
                )

            # Add bot response to session history
            session.add_message("assistant", response_text)

            # Save session to persistence
            await self.session_manager.save_session(session)

            logger.info("Successfully processed %s message from user %s", message_type, chat_id)
            return response_text

        except LLMError as e:
            logger.exception("LLM error processing %s message from user %s", message_type, chat_id)
            return get_user_friendly_error_message(e)

        except Exception as e:
            logger.exception("Unexpected error processing %s message from user %s", message_type, chat_id)
            return get_user_friendly_error_message(e)

    async def _extract_message_content(
        self, message: Message, message_type: str
    ) -> Optional[str]:
        """
        Extract content from message based on type.

        Args:
            message: Telegram message object
            message_type: Type of message

        Returns:
            Extracted content or None if failed
        """
        if message_type == "text":
            return message.text or ""

        elif message_type == "voice":
            return await self._transcribe_voice_message(message)

        elif message_type in ("photo", "document"):
            return await self._extract_media_content(message, message_type)

        else:
            logger.warning("Unknown message type: %s", message_type)
            return None

    async def _transcribe_voice_message(self, message: Message) -> Optional[str]:
        """
        Transcribe voice message to text.

        Args:
            message: Telegram message object with voice

        Returns:
            Transcribed text or None if failed
        """
        try:
            # Import here to avoid circular imports
            from bot.handlers import media_handlers

            if not media_handlers:
                logger.error("Media handlers not initialized for transcription")
                return None

            # Get current session context
            session = await self.session_manager.get_session(message.chat.id)
            session_context = session.to_dict() if session else {}

            # Process audio to get transcript
            result = await media_handlers.media_processor.process_media(
                file_id=message.voice.file_id,
                file_type="voice",
                chat_id=str(message.chat.id),
                session_context=session_context,
            )

            if "error" in result:
                logger.error("Audio transcription error: %s", result["error"])
                return None

            transcript = result.get("transcript", "")
            if not transcript:
                logger.warning("No transcript returned from audio processing")
                return None

            logger.info("Audio transcribed successfully: %s", transcript[:100])
            return transcript

        except Exception as e:
            logger.error("Error transcribing voice message: %s", e, exc_info=True)
            return None

    async def _extract_media_content(
        self, message: Message, message_type: str
    ) -> Optional[str]:
        """
        Extract content from media message (photo/document).

        Args:
            message: Telegram message object
            message_type: Type of media ('photo' or 'document')

        Returns:
            Extracted content or None if failed
        """
        try:
            # Import here to avoid circular imports
            from core.image_processor import ImageProcessor

            # Get current session context
            session = await self.session_manager.get_session(message.chat.id)
            session_context = session.to_dict() if session else {}

            # Determine file_id based on message type
            if message_type == "photo":
                photo = message.photo[-1] if message.photo else None
                if not photo:
                    return None
                file_id = photo.file_id
            elif message_type == "document":
                document = message.document
                if not document or not document.mime_type or not document.mime_type.startswith("image/"):
                    return "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ñ Ð¿Ð¾ÐºÐ° Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÑŽ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ."
                file_id = document.file_id
            else:
                return None

            # Process image with new ImageProcessor
            from core.bot_instance import get_bot_instance
            bot = get_bot_instance()
            image_processor = ImageProcessor(bot)
            result = await image_processor.process_image_for_analysis(
                file_id=file_id,
                session_context=session_context,
            )

            if "error" in result:
                logger.error("Media processing error: %s", result["error"])
                return None

            # Update session with image analysis results
            if session:
                # Set scenario to image_analysis
                session.scenario = "image_analysis"
                
                # Update image analysis fields
                import json
                session.last_image_analysis = json.dumps(result)
                session.image_analysis_count += 1
                
                # Add message with image flag
                extracted_text = result.get("extracted_text", "")
                content_type = result.get("content_type", message_type)
                content = f"[{content_type}] {extracted_text}" if extracted_text else f"[{content_type}] Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾"
                
                session.add_message("user", content)
                await self.session_manager.save_session(session)

            # Add new fields to session context for response generation
            enhanced_context = session_context.copy()
            enhanced_context.update({
                "visual_elements": result.get("visual_elements", ""),
                "discussion_points": result.get("discussion_points", []),
                "interest_level": result.get("interest_level", "medium")
            })
            
            # Generate educational response based on image analysis
            return await self._generate_image_analysis_response(result, enhanced_context)

        except Exception as e:
            logger.error("Error extracting media content: %s", e, exc_info=True)
            return None

    def _create_synthetic_message(
        self, transcript: str, original_message: Message
    ) -> Message:
        """
        Create synthetic message object from transcript.

        Args:
            transcript: Transcribed text
            original_message: Original message object

        Returns:
            Synthetic message object with transcript as text
        """
        # Create a copy of the original message with transcript as text
        synthetic_message = original_message.model_copy(
            update={
                'text': transcript,
                'voice': None,
                'photo': None,
                'document': None,
                'content_type': 'text'
            }
        )
        return synthetic_message

    async def _generate_image_analysis_response(
        self, analysis_result: dict, session_context: dict
    ) -> str:
        """
        Generate educational response based on image analysis.

        Args:
            analysis_result: Image analysis results
            session_context: Current session context

        Returns:
            Generated response text
        """
        try:
            content_type = analysis_result.get("content_type", "unknown")
            extracted_text = analysis_result.get("extracted_text", "")
            subject = analysis_result.get("subject", "general")
            topic = analysis_result.get("topic", "unknown")
            complexity_level = analysis_result.get("complexity_level", 5)
            questions = analysis_result.get("questions", [])
            educational_value = analysis_result.get("educational_value", "medium")

            # Generate more engaging and varied responses
            return await self._generate_engaging_response(
                content_type, extracted_text, subject, topic, 
                complexity_level, questions, educational_value, session_context
            )

        except Exception as e:
            logger.error("Error generating image analysis response: %s", e, exc_info=True)
            return "Ð¯ Ð¿Ð¾Ð»ÑƒÑ‡Ð¸Ð» Ð²Ð°ÑˆÐµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ. Ð Ð°ÑÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ, Ñ‡Ñ‚Ð¾ Ð²Ñ‹ Ñ…Ð¾Ñ‚ÐµÐ»Ð¸ Ð±Ñ‹ ÑƒÐ·Ð½Ð°Ñ‚ÑŒ Ð¾Ð± ÑÑ‚Ð¾Ð¼?"

    async def _generate_engaging_response(
        self, content_type: str, extracted_text: str, subject: str, 
        topic: str, complexity_level: int, questions: list, 
        educational_value: str, session_context: dict
    ) -> str:
        """Generate engaging and varied responses based on image analysis."""
        import random
        
        # Get additional fields from analysis result
        visual_elements = session_context.get("visual_elements", "")
        discussion_points = session_context.get("discussion_points", [])
        interest_level = session_context.get("interest_level", "medium")
        
        # Get user's learning preferences from session context
        user_level = session_context.get("user_level", "intermediate")
        interests = session_context.get("interests", [])
        
        # Different response styles based on content type and complexity
        if content_type == "math_problem":
            return self._generate_math_response(extracted_text, topic, complexity_level, questions, interest_level)
        
        elif content_type == "diagram":
            return self._generate_diagram_response(extracted_text, topic, subject, complexity_level, visual_elements)
        
        elif content_type == "text":
            return self._generate_text_response(extracted_text, topic, subject, questions, discussion_points)
        
        elif content_type == "photo":
            return self._generate_photo_response(extracted_text, topic, subject, educational_value, visual_elements, interest_level)
        
        elif content_type == "chart":
            return self._generate_chart_response(extracted_text, topic, subject, complexity_level, visual_elements)
        
        else:
            return self._generate_general_response(extracted_text, topic, subject, educational_value, visual_elements, interest_level)

    def _generate_math_response(self, extracted_text: str, topic: str, complexity_level: int, questions: list, interest_level: str) -> str:
        """Generate engaging response for mathematical content."""
        import random
        
        if extracted_text:
            # Vary the opening based on complexity and interest level
            if interest_level == "high":
                if complexity_level >= 7:
                    openings = [
                        "ÐžÐ³Ð¾, ÑÑ‚Ð¾ Ð²Ñ‹Ð³Ð»ÑÐ´Ð¸Ñ‚ ÐºÐ°Ðº ÑÐµÑ€ÑŒÐµÐ·Ð½Ð°Ñ Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°! ðŸ”¢",
                        "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾! Ð¡Ð»Ð¾Ð¶Ð½Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°, Ð½Ð¾ Ð¼Ñ‹ ÑÐ¿Ñ€Ð°Ð²Ð¸Ð¼ÑÑ! ðŸ’ª",
                        "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°! Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ñ€Ð°Ð·Ð±ÐµÑ€ÐµÐ¼ ÐµÑ‘ Ð¿Ð¾ Ñ‡Ð°ÑÑ‚ÑÐ¼! ðŸ§®"
                    ]
                elif complexity_level >= 4:
                    openings = [
                        "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð°Ñ Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°! ðŸŽ¯",
                        "Ð¯ Ð²Ð¸Ð¶Ñƒ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½ÑƒÑŽ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð¿Ð¾ Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐµ! âœ¨",
                        "Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ñ€ÐµÑˆÐ¸Ð¼ ÑÑ‚Ñƒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð²Ð¼ÐµÑÑ‚Ðµ! ðŸ¤“"
                    ]
                else:
                    openings = [
                        "ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð¸ Ð¿Ð¾Ð½ÑÑ‚Ð½Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°! ðŸ‘",
                        "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¸Ð¼ÐµÑ€ Ð´Ð»Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ! ðŸ“š",
                        "Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ñ€Ð°Ð·Ð±ÐµÑ€ÐµÐ¼ ÑÑ‚Ñƒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð¿Ð¾ÑˆÐ°Ð³Ð¾Ð²Ð¾! ðŸŽ“"
                    ]
            else:
                openings = [
                    "ÐœÐ°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°! ðŸ§®",
                    "Ð”Ð°Ð²Ð°Ð¹Ñ‚Ðµ Ñ€Ð°Ð·Ð±ÐµÑ€ÐµÐ¼ ÑÑ‚Ñƒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ! ðŸ“Š",
                    "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð°Ñ Ð·Ð°Ð´Ð°Ñ‡Ð° Ð¿Ð¾ Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐµ! âœ¨"
                ]
            
            opening = random.choice(openings)
            
            # Add engaging follow-up
            follow_ups = [
                "Ð§Ñ‚Ð¾ Ñ‚Ñ‹ Ð´ÑƒÐ¼Ð°ÐµÑˆÑŒ, Ñ Ñ‡ÐµÐ³Ð¾ Ð½Ð°Ð¼ ÑÑ‚Ð¾Ð¸Ñ‚ Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ?",
                "ÐšÐ°ÐºÐ°Ñ Ñ‡Ð°ÑÑ‚ÑŒ Ð·Ð°Ð´Ð°Ñ‡Ð¸ ÐºÐ°Ð¶ÐµÑ‚ÑÑ Ñ‚ÐµÐ±Ðµ ÑÐ°Ð¼Ð¾Ð¹ Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾Ð¹?",
                "Ð•ÑÑ‚ÑŒ Ð»Ð¸ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ñ‚ÐµÐ±Ñ ÑÐ¼ÑƒÑ‰Ð°ÐµÑ‚ Ð² ÑƒÑÐ»Ð¾Ð²Ð¸Ð¸?",
                "ÐšÐ°ÐºÐ¾Ð¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ Ðº Ñ€ÐµÑˆÐµÐ½Ð¸ÑŽ Ñ‚Ñ‹ Ð±Ñ‹ Ð²Ñ‹Ð±Ñ€Ð°Ð»?"
            ]
            
            return f"{opening}\n\n{extracted_text}\n\n{random.choice(follow_ups)}"
        else:
            return f"Ð¯ Ð²Ð¸Ð¶Ñƒ Ð¼Ð°Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð·Ð°Ð´Ð°Ñ‡Ñƒ Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ '{topic}'! ðŸ§® Ð§Ñ‚Ð¾ Ð¸Ð¼ÐµÐ½Ð½Ð¾ Ñ‚Ñ‹ Ñ…Ð¾Ñ‡ÐµÑˆÑŒ Ñ€Ð°Ð·Ð¾Ð±Ñ€Ð°Ñ‚ÑŒ Ð² ÑÑ‚Ð¾Ð¹ Ð·Ð°Ð´Ð°Ñ‡Ðµ?"

    def _generate_diagram_response(self, extracted_text: str, topic: str, subject: str, complexity_level: int, visual_elements: str) -> str:
        """Generate engaging response for diagrams and schemas."""
        import random
        
        if extracted_text:
            openings = [
                "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð°Ñ ÑÑ…ÐµÐ¼Ð°! ðŸ“Š",
                "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð°Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ð°! ðŸŽ¨",
                "ÐŸÐ¾Ð½ÑÑ‚Ð½Ð°Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ! ðŸ‘€",
                "Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ ÑÑ…ÐµÐ¼Ð°! ðŸ“‹"
            ]
            
            opening = random.choice(openings)
            
            follow_ups = [
                "Ð§Ñ‚Ð¾ Ñ‚ÐµÐ±Ðµ ÐºÐ°Ð¶ÐµÑ‚ÑÑ ÑÐ°Ð¼Ñ‹Ð¼ Ð²Ð°Ð¶Ð½Ñ‹Ð¼ Ð² ÑÑ‚Ð¾Ð¹ ÑÑ…ÐµÐ¼Ðµ?",
                "Ð•ÑÑ‚ÑŒ Ð»Ð¸ ÑÐ²ÑÐ·Ð¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ñ‚Ñ‹ Ð½Ðµ Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÐµÑˆÑŒ?",
                "ÐšÐ°Ðº Ð±Ñ‹ Ñ‚Ñ‹ Ð¾Ð±ÑŠÑÑÐ½Ð¸Ð» ÑÑ‚Ñƒ ÑÑ…ÐµÐ¼Ñƒ Ð´Ñ€ÑƒÐ³Ñƒ?",
                "Ð§Ñ‚Ð¾ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ñ‚Ñ‹ ÑƒÐ·Ð½Ð°Ð» Ð¸Ð· ÑÑ‚Ð¾Ð¹ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ñ‹?"
            ]
            
            response = f"{opening}\n\n{extracted_text}\n\n{random.choice(follow_ups)}"
            
            # Add visual elements if available
            if visual_elements:
                response += f"\n\nÐžÐ±Ñ€Ð°Ñ‚Ð¸ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð½Ð°: {visual_elements}"
            
            return response
        else:
            return f"Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð°Ñ ÑÑ…ÐµÐ¼Ð° Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ '{topic}'! ðŸ“Š Ð Ð°ÑÑÐºÐ°Ð¶Ð¸, Ñ‡Ñ‚Ð¾ Ñ‚Ñ‹ Ð²Ð¸Ð´Ð¸ÑˆÑŒ Ð½Ð° ÑÑ‚Ð¾Ð¹ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ðµ?"

    def _generate_text_response(self, extracted_text: str, topic: str, subject: str, questions: list, discussion_points: list) -> str:
        """Generate engaging response for text content."""
        import random
        
        if extracted_text:
            # Check if it's a historical or literary text
            if subject in ["history", "literature", "language"]:
                openings = [
                    "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ð¹ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚! ðŸ“œ",
                    "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð½Ñ‹Ð¹ Ð¾Ñ‚Ñ€Ñ‹Ð²Ð¾Ðº! ðŸ“–",
                    "ÐŸÐ¾Ð·Ð½Ð°Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚! ðŸŽ“"
                ]
            else:
                openings = [
                    "ÐŸÐ¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚! ðŸ“",
                    "Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»! ðŸ“š",
                    "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾Ðµ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸Ðµ! âœ¨"
                ]
            
            opening = random.choice(openings)
            
            follow_ups = [
                "Ð§Ñ‚Ð¾ Ñ‚ÐµÐ±Ñ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð²ÑÐµÐ³Ð¾ Ð·Ð°Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ¾Ð²Ð°Ð»Ð¾ Ð² ÑÑ‚Ð¾Ð¼ Ñ‚ÐµÐºÑÑ‚Ðµ?",
                "Ð•ÑÑ‚ÑŒ Ð»Ð¸ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ñ?",
                "ÐšÐ°Ðº Ñ‚Ñ‹ Ð¿Ð¾Ð½Ð¸Ð¼Ð°ÐµÑˆÑŒ Ð¾ÑÐ½Ð¾Ð²Ð½ÑƒÑŽ Ð¸Ð´ÐµÑŽ ÑÑ‚Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°?",
                "ÐšÐ°ÐºÐ¸Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ñƒ Ñ‚ÐµÐ±Ñ Ð²Ð¾Ð·Ð½Ð¸ÐºÐ»Ð¸ Ð¿Ð¾ÑÐ»Ðµ Ð¿Ñ€Ð¾Ñ‡Ñ‚ÐµÐ½Ð¸Ñ?"
            ]
            
            response = f"{opening}\n\n{extracted_text}\n\n{random.choice(follow_ups)}"
            
            # Add discussion points if available
            if discussion_points:
                response += f"\n\nÐœÐ¾Ð¶ÐµÐ¼ Ð¾Ð±ÑÑƒÐ´Ð¸Ñ‚ÑŒ: {', '.join(discussion_points[:3])}"
            
            return response
        else:
            return f"Ð¯ Ð²Ð¸Ð¶Ñƒ Ñ‚ÐµÐºÑÑ‚ Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ '{topic}'! ðŸ“ Ð§Ñ‚Ð¾ Ð¸Ð¼ÐµÐ½Ð½Ð¾ Ñ‚Ñ‹ Ñ…Ð¾Ñ‡ÐµÑˆÑŒ Ð¾Ð±ÑÑƒÐ´Ð¸Ñ‚ÑŒ?"

    def _generate_photo_response(self, extracted_text: str, topic: str, subject: str, educational_value: str, visual_elements: str, interest_level: str) -> str:
        """Generate engaging response for photos."""
        import random
        
        if educational_value == "high":
            openings = [
                "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾Ðµ Ð¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ! ðŸŽ“",
                "ÐžÑ‡ÐµÐ½ÑŒ Ð¿Ð¾Ð·Ð½Ð°Ð²Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ñ„Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ñ! ðŸ“¸",
                "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ñ‹Ð¹ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð» Ð´Ð»Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ! ðŸ”"
            ]
        else:
            openings = [
                "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ! ðŸ“·",
                "ÐšÑ€Ð°ÑÐ¸Ð²Ð°Ñ Ñ„Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ñ! âœ¨",
                "Ð›ÑŽÐ±Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹Ð¹ ÑÐ½Ð¸Ð¼Ð¾Ðº! ðŸ‘€"
            ]
        
        opening = random.choice(openings)
        
        follow_ups = [
            "Ð§Ñ‚Ð¾ Ñ‚Ñ‹ Ð²Ð¸Ð´Ð¸ÑˆÑŒ Ð½Ð° ÑÑ‚Ð¾Ð¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸?",
            "ÐšÐ°ÐºÐ¸Ðµ Ð´ÐµÑ‚Ð°Ð»Ð¸ Ñ‚ÐµÐ±Ñ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð²ÑÐµÐ³Ð¾ Ð·Ð°Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ¾Ð²Ð°Ð»Ð¸?",
            "Ð§Ñ‚Ð¾ Ñ‚Ñ‹ Ð´ÑƒÐ¼Ð°ÐµÑˆÑŒ Ð¾Ð± ÑÑ‚Ð¾Ð¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸?",
            "Ð•ÑÑ‚ÑŒ Ð»Ð¸ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ Ñ‚ÐµÐ±Ñ ÑƒÐ´Ð¸Ð²Ð¸Ð»Ð¾?"
        ]
        
        response = f"{opening}\n\n{random.choice(follow_ups)}"
        
        # Add visual elements if available and interesting
        if visual_elements and interest_level == "high":
            response += f"\n\nÐžÐ±Ñ€Ð°Ñ‚Ð¸ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð½Ð°: {visual_elements}"
        
        return response

    def _generate_chart_response(self, extracted_text: str, topic: str, subject: str, complexity_level: int, visual_elements: str) -> str:
        """Generate engaging response for charts and graphs."""
        import random
        
        if extracted_text:
            openings = [
                "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð°Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ð° Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸! ðŸ“Š",
                "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð°Ñ Ð²Ð¸Ð·ÑƒÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ! ðŸ“ˆ",
                "ÐŸÐ¾Ð½ÑÑ‚Ð½Ñ‹Ð¹ Ð³Ñ€Ð°Ñ„Ð¸Ðº! ðŸ“‰"
            ]
            
            opening = random.choice(openings)
            
            follow_ups = [
                "Ð§Ñ‚Ð¾ Ð¿Ð¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÑŽÑ‚ ÑÑ‚Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ?",
                "ÐšÐ°ÐºÐ¸Ðµ Ð²Ñ‹Ð²Ð¾Ð´Ñ‹ Ñ‚Ñ‹ Ð¼Ð¾Ð¶ÐµÑˆÑŒ ÑÐ´ÐµÐ»Ð°Ñ‚ÑŒ?",
                "Ð§Ñ‚Ð¾ Ñ‚ÐµÐ±Ñ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð²ÑÐµÐ³Ð¾ ÑƒÐ´Ð¸Ð²Ð¸Ð»Ð¾ Ð² ÑÑ‚Ð¾Ð¹ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ðµ?",
                "ÐšÐ°Ðº Ð±Ñ‹ Ñ‚Ñ‹ Ð¾Ð±ÑŠÑÑÐ½Ð¸Ð» ÑÑ‚Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ðµ?"
            ]
            
            response = f"{opening}\n\n{extracted_text}\n\n{random.choice(follow_ups)}"
            
            # Add visual elements if available
            if visual_elements:
                response += f"\n\nÐžÐ±Ñ€Ð°Ñ‚Ð¸ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð½Ð°: {visual_elements}"
            
            return response
        else:
            return f"Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð°Ñ Ð´Ð¸Ð°Ð³Ñ€Ð°Ð¼Ð¼Ð° Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ '{topic}'! ðŸ“Š Ð§Ñ‚Ð¾ Ñ‚Ñ‹ Ð²Ð¸Ð´Ð¸ÑˆÑŒ Ð² ÑÑ‚Ð¸Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…?"

    def _generate_general_response(self, extracted_text: str, topic: str, subject: str, educational_value: str, visual_elements: str, interest_level: str) -> str:
        """Generate engaging response for general content."""
        import random
        
        openings = [
            "Ð˜Ð½Ñ‚ÐµÑ€ÐµÑÐ½Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ! ðŸ¤”",
            "Ð›ÑŽÐ±Ð¾Ð¿Ñ‹Ñ‚Ð½Ñ‹Ð¹ Ð¼Ð°Ñ‚ÐµÑ€Ð¸Ð°Ð»! ðŸ‘€",
            "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð¸Ð·ÑƒÑ‡ÐµÐ½Ð¸Ñ! ðŸ“š"
        ]
        
        opening = random.choice(openings)
        
        follow_ups = [
            "Ð§Ñ‚Ð¾ Ñ‚Ñ‹ Ð²Ð¸Ð´Ð¸ÑˆÑŒ Ð½Ð° ÑÑ‚Ð¾Ð¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸?",
            "ÐšÐ°ÐºÐ¸Ðµ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ñƒ Ñ‚ÐµÐ±Ñ Ð²Ð¾Ð·Ð½Ð¸ÐºÐ»Ð¸?",
            "Ð§Ñ‚Ð¾ Ñ‚ÐµÐ±Ñ Ð±Ð¾Ð»ÑŒÑˆÐµ Ð²ÑÐµÐ³Ð¾ Ð·Ð°Ð¸Ð½Ñ‚ÐµÑ€ÐµÑÐ¾Ð²Ð°Ð»Ð¾?",
            "ÐšÐ°Ðº Ñ‚Ñ‹ Ð´ÑƒÐ¼Ð°ÐµÑˆÑŒ, Ñ‡Ñ‚Ð¾ ÑÑ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¾Ð·Ð½Ð°Ñ‡Ð°Ñ‚ÑŒ?"
        ]
        
        response = f"{opening}\n\n{random.choice(follow_ups)}"
        
        # Add visual elements if available and interesting
        if visual_elements and interest_level == "high":
            response += f"\n\nÐžÐ±Ñ€Ð°Ñ‚Ð¸ Ð²Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ Ð½Ð°: {visual_elements}"
        
        return response


# Global unified message processor instance
_unified_processor: Optional[UnifiedMessageProcessor] = None


def get_unified_processor() -> UnifiedMessageProcessor:
    """Get global unified message processor instance."""
    global _unified_processor  # noqa: PLW0603
    if _unified_processor is None:
        _unified_processor = UnifiedMessageProcessor()
    return _unified_processor
